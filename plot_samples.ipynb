{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options import Options\n",
    "options = Options(batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "IF_DATA_AUGMENTATION = True\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_WIDTH = IMAGE_HEIGHT = 224\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 1\n",
    "INPUT_SHAPE = [IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "If in eager mode:  True\nUse tensorflow version 2.\nLoad config ...\nROOT_PATH: D:\\DeepLearningData\\semi-conductor-image-classification-first\nROOT_PATH: D:\\DeepLearningData\\semi-conductor-image-classification-first\nTRAIN_DATA_DIR: D:\\DeepLearningData\\semi-conductor-image-classification-first\\data\\origin\\train\\\nTEST_DATA_DIR: D:\\DeepLearningData\\semi-conductor-image-classification-first\\data\\origin\\test\\all_tests\n"
    }
   ],
   "source": [
    "print(\"If in eager mode: \", tf.executing_eagerly())\n",
    "print(\"Use tensorflow version 2.\")\n",
    "assert tf.__version__[0] == \"2\"\n",
    "\n",
    "print(\"Load config ...\")\n",
    "with open('./config/config_win.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "ROOT_PATH = CONFIG[\"ROOT_PATH\"]\n",
    "print(f\"ROOT_PATH: {ROOT_PATH}\")\n",
    "ROOT_PATH = os.path.expanduser(ROOT_PATH)\n",
    "print(f\"ROOT_PATH: {ROOT_PATH}\")\n",
    "TRAIN_DATA_DIR = os.path.join(ROOT_PATH, CONFIG[\"TRAIN_DATA_DIR\"])\n",
    "print(f\"TRAIN_DATA_DIR: {TRAIN_DATA_DIR}\")\n",
    "TEST_DATA_DIR = os.path.join(ROOT_PATH, CONFIG[\"TEST_DATA_DIR\"])\n",
    "print(f\"TEST_DATA_DIR: {TEST_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prepare testing data...\n"
    }
   ],
   "source": [
    "test_on_train = True\n",
    "\n",
    "print(\"Prepare testing data...\")\n",
    "if test_on_train:\n",
    "    num_samples = num_train = 30000\n",
    "    label_names = os.listdir(TRAIN_DATA_DIR)\n",
    "    filenames, labels = [], []\n",
    "    for i, label in enumerate(label_names):\n",
    "        files = os.listdir(os.path.join(TRAIN_DATA_DIR, label))\n",
    "        for f in files:\n",
    "            filenames.append(label+\"/\"+f)\n",
    "            labels.append(i)  # 0 or 1\n",
    "    table = np.asarray([filenames, labels])\n",
    "    table = table.T\n",
    "    columns = [\"filename\", \"label\"]\n",
    "    # test on train dataset\n",
    "    test_df = pd.DataFrame(data=table, columns=columns)\n",
    "else:\n",
    "    test_filenames = os.listdir(TEST_DATA_DIR)\n",
    "    test_df = pd.DataFrame({\n",
    "        'filename': test_filenames\n",
    "    })\n",
    "    num_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, ..., 1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# test_df[\"label\"].dtypes\n",
    "# test_df.dtypes\n",
    "label = test_df[\"label\"].to_numpy(dtype=int)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using real-time data augmentation.\nTraining Generator...\nFound 24000 images belonging to 2 classes.\nValidation Generator...\nFound 6000 images belonging to 2 classes.\nTrain class_indices:  {'good_0': 0, 'bad_1': 1}\nVal class_indices:  {'good_0': 0, 'bad_1': 1}\n"
    }
   ],
   "source": [
    "classes = [\"good_0\", \"bad_1\"]\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "print(\"Training Generator...\")\n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    subset='training',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    classes=classes,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=options.batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Validation Generator...\")\n",
    "valid_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    subset='validation',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    classes=classes,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=options.batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Train class_indices: \", train_generator.class_indices)\n",
    "print(\"Val class_indices: \", validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24000"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(train_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6000"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(validation_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "classes: ['good_0', 'bad_1']\ncount: 21600\n"
    }
   ],
   "source": [
    "print(f\"classes: {classes}\")\n",
    "# l = validation_generator.filenames\n",
    "l = train_generator.filenames\n",
    "count = 0\n",
    "for f in l:\n",
    "    if f.startswith(classes[0]):\n",
    "        count += 1\n",
    "print(f\"count: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}